{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9268d0d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Authorship Detection\n",
    "# Ameen Mohamed\n",
    "# Project: Feature Extraction & Classification (ML)\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK data for stopwords and wordnet if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# ml\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Setup\n",
    "random.seed(42)\n",
    "\n",
    "# =====================================\n",
    "# 1) DATASET PREPARATION\n",
    "# =====================================\n",
    "texts_data = {\n",
    "    \"Shakespeare\": [\n",
    "        \"To be, or not to be: that is the question.\",\n",
    "        \"All the world's a stage, and all the men and women merely players.\",\n",
    "        \"Some are born great, some achieve greatness, and some have greatness thrust upon them.\",\n",
    "        \"The course of true love never did run smooth.\",\n",
    "        \"Love all, trust a few, do wrong to none.\",\n",
    "        \"Cowards die many times before their deaths; the valiant never taste of death but once.\"\n",
    "    ],\n",
    "    \"Jane Austen\": [\n",
    "        \"It is a truth universally acknowledged, that a single man in possession of a good fortune must be in want of a wife.\",\n",
    "        \"A lady's imagination is very rapid; it jumps from admiration to love, from love to matrimony.\",\n",
    "        \"There is no charm equal to tenderness of heart.\",\n",
    "        \"I declare after all there is no enjoyment like reading!\",\n",
    "        \"Vanity and pride are different things, though the words are often used synonymously.\",\n",
    "        \"One half of the world cannot understand the pleasures of the other.\"\n",
    "    ],\n",
    "    \"Mark Twain\": [\n",
    "        \"The secret of getting ahead is getting started.\",\n",
    "        \"Kindness is the language which the deaf can hear and the blind can see.\",\n",
    "        \"Truth is stranger than fiction, but it is because Fiction is obliged to stick to possibilities.\",\n",
    "        \"The lack of money is the root of all evil.\",\n",
    "        \"The best way to cheer yourself up is to try to cheer somebody else up.\",\n",
    "        \"Courage is resistance to fear, mastery of fear, not absence of fear.\"\n",
    "    ],\n",
    "    \"Charles Dickens\": [\n",
    "        \"It was the best of times, it was the worst of times.\",\n",
    "        \"Have a heart that never hardens, and a temper that never tires.\",\n",
    "        \"A loving heart is the truest wisdom.\",\n",
    "        \"No one is useless in this world who lightens the burden of another.\",\n",
    "        \"There is a wisdom of the head, and a wisdom of the heart.\",\n",
    "        \"We forge the chains we wear in life.\"\n",
    "    ],\n",
    "    \"Edgar Allan Poe\": [\n",
    "        \"I became insane, with long intervals of horrible sanity.\",\n",
    "        \"All that we see or seem is but a dream within a dream.\",\n",
    "        \"Words have no power to impress the mind without the exquisite horror of their reality.\",\n",
    "        \"Those who dream by day are cognizant of many things which escape those who dream only by night.\",\n",
    "        \"The boundaries which divide Life from Death are at best shadowy and vague.\",\n",
    "        \"There is no beauty without some strangeness.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# transform data to lists and tables\n",
    "data_list = []\n",
    "for author, sentences in texts_data.items():\n",
    "    for sent in sentences:\n",
    "        data_list.append({\"text\": sent, \"label\": author})\n",
    "\n",
    "df = pd.DataFrame(data_list)\n",
    "print(f\"Total Samples: {len(df)}\")\n",
    "print(df.head())\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# =====================================\n",
    "# 2) PREPROCESSING\n",
    "# =====================================\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    cleaned = []\n",
    "    for w in tokens:\n",
    "        if w.isalpha():\n",
    "            if w not in STOPWORDS:\n",
    "                cleaned.append(lemmatizer.lemmatize(w))\n",
    "    return \" \".join(cleaned)\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# =====================================\n",
    "# 3) EXPERIMENT: COMPARE 3 TECHNIQUES\n",
    "# =====================================\n",
    "\n",
    "# Split Data (80% Train, 20% Test)\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    df['cleaned_text'], df['label'], test_size=0.3, random_state=42, stratify=df['label']\n",
    ")\n",
    "\n",
    "# تعريف الـ 3 طرق المطلوبة\n",
    "feature_extractors = {\n",
    "    \"1. Binary Encoding\": CountVectorizer(binary=True),\n",
    "    \"2. Count Encoding\":  CountVectorizer(binary=False),\n",
    "    \"3. TF-IDF\":          TfidfVectorizer()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"\\n=== STARTING EVALUATION ===\\n\")\n",
    "\n",
    "for name, vectorizer in feature_extractors.items():\n",
    "    print(f\"Applying: {name} ...\")\n",
    "\n",
    "    # 1. Transform Text to Numbers (Feature Extraction)\n",
    "    X_train = vectorizer.fit_transform(X_train_text)\n",
    "    X_test  = vectorizer.transform(X_test_text)\n",
    "\n",
    "    # 2. Train Classifier (Naive Bayes)\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # 3. Predict & Evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # تخزين النتائج\n",
    "    results.append({\"Technique\": name, \"Accuracy\": acc})\n",
    "\n",
    "    print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# =====================================\n",
    "# 4) FINAL REPORT\n",
    "# =====================================\n",
    "print(\"\\n=== FINAL COMPARISON REPORT ===\")\n",
    "final_df = pd.DataFrame(results).sort_values(by=\"Accuracy\", ascending=False)\n",
    "print(final_df)\n",
    "\n",
    "best_method = final_df.iloc[0]['Technique']\n",
    "print(f\"\\n✅ The best performing technique for this dataset is: {best_method}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
